{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae37f5d1-e38d-409f-9ab6-b54556d79eb9",
   "metadata": {},
   "source": [
    "### Text comprehension through spaCy\n",
    "\n",
    "This notebook is an example of topic modeling adapted from [this writeup](https://medium.com/@sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06).\n",
    "\n",
    "It showcases some of the linguistic analysis features that spaCy offers. \n",
    "\n",
    "The libraries we will use are:\n",
    "- `pandas`: for reading in and exporting spreadsheets\n",
    "- `spacy`: a natural language processing library that contains various models trained on various languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced40d95-a0fd-45bc-8e3d-018afc307fe6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47309a2e-25da-4775-8139-1ef3b214fe5a",
   "metadata": {},
   "source": [
    "#### Let's load spaCy's English language trained pipeline\n",
    "\n",
    "`A training pipeline typically reads training data from a feature store, performs model-dependent transformations, trains the model, and evaluates the model before the model is saved to a model registry.`\n",
    "\n",
    "You will need to download one of spaCy's models and can do so by typing this into a cell here:\n",
    "```\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f8d12-1144-467a-bbaa-ef2700fe5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09006585-4b45-45c9-9578-02a9abe0d124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920de05e-8a0e-4ee1-943a-e40900d5a589",
   "metadata": {},
   "source": [
    "Now we can run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0d3b6-cebb-4c38-85f6-685db54eca66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d16ede22-827e-485f-86ae-9dfe805d8351",
   "metadata": {},
   "source": [
    "## Computational Linguistics\n",
    "\n",
    "#### POS-Tagging — (Part Of Speech)\n",
    "spaCy has a nifty way to look into how each word is used in a sentence, often also referred to as Part Of Speech (POS). There are eight main parts of speech — nouns, pronouns, adjectives, verbs, adverbs, prepositions, conjunctions, and interjections. \n",
    "\n",
    "Once we have turned our sentence into an NLP object we can look at the token (meaning the individual words) it consists of and two types of tags to represent what part of speech each word is on a higher and on a more granular level. \n",
    "\n",
    "You can find various tags here and their explanations [here](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/13-POS-Keywords.html#spacy-part-of-speech-tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d730166-04c3-41ca-b14d-28f2151bd37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918f4244-3e7f-421a-bcd9-1b6cb96cad2c",
   "metadata": {},
   "source": [
    "#### NER-Tagging — (Named Entity Recognition)\n",
    "Named-entity recognition (NER) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "\n",
    "SpaCy recognizes the following built-in entity types:\n",
    "- PERSON - People, including fictional.\n",
    "- NORP - Nationalities or religious or political groups.\n",
    "- FAC - Buildings, airports, highways, bridges, etc.\n",
    "- ORG - Companies, agencies, institutions, etc.\n",
    "- GPE - Countries, cities, states.\n",
    "- LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "- PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "- EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "- WORK_OF_ART - Titles of books, songs, etc.\n",
    "- LAW - Named documents made into laws.\n",
    "- LANGUAGE - Any named language.\n",
    "- DATE - Absolute or relative dates or periods.\n",
    "- TIME - Times smaller than a day.\n",
    "- PERCENT - Percentage, including \"%\".\n",
    "- MONEY - Monetary values, including unit.\n",
    "- QUANTITY - Measurements, as of weight or distance.\n",
    "- ORDINAL - \"first\", \"second\", etc.\n",
    "- CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16ce0b-8362-4aed-a1d5-737898f38c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7de4f5-727d-4313-9745-49ed04cbadc1",
   "metadata": {},
   "source": [
    "Let's run a slightly different version of this code to see what role these things play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23721041-a1b2-4c3f-b0e8-98b7d32a3cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e1ebccf-1168-4c74-9f42-aef062dbfa86",
   "metadata": {},
   "source": [
    "You can render these roles visually, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff04120-57a7-4902-b43c-3d1db84ed3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f44ebb-9272-4ac6-8173-a32654f6a408",
   "metadata": {},
   "source": [
    "### Sentiment analysis\n",
    "spaCy also has some sentiment analysis tools baked into its library. For some rudimentary sentiment analysis we will be using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbeef51-1283-4d97-b23e-1540e9c18b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install spacytextblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686c795-8120-4f91-806d-3dca7ad02971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b555882c-7a7c-4de9-8492-41f1e6129b93",
   "metadata": {},
   "source": [
    "As before let's load our model. We'll also load [`spacytextblob`](https://spacy.io/universe/project/spacy-textblob) which as an adaptation of a popular library for sentiment analysis called [`textblob`](https://textblob.readthedocs.io/en/latest/quickstart.html). And funnily enough, textblob's sentiment analysis is based on yet another library called pattern.\n",
    "\n",
    "According to [investigate.ai](https://investigate.ai/investigating-sentiment-analysis/comparing-sentiment-analysis-tools/#TextBlob), \"The sentiment analysis lexicon bundled in Pattern focuses on adjectives. It contains adjectives that occur frequently in customer reviews, hand-tagged with values for polarity and subjectivity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f088c00-fbde-45b5-a621-4a331db314a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb62607-bb83-4016-a4a2-3b96f8649a83",
   "metadata": {},
   "source": [
    "Then we can get started. Here's a sample text that we will turn into a spaCy document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb61f6-52b0-4f4e-b12f-9ca9e469fc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "590b5dba-6c6e-442b-808a-ecd3ab70c38c",
   "metadata": {},
   "source": [
    "Once we have done this we can start analyzing it by:\n",
    "- polarity\n",
    "- subjectivity\n",
    "- overall sentiment assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c947a6-8ffa-4415-8d9f-67828303e26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783c4b4-e6f6-4b39-b328-7b2e8cb0073d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d773aa-f919-4a69-94f7-85fb19c54116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210ab1b-ee4c-4329-87b0-876d7388cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ad20730-da4a-47f8-8b44-e7697adfe298",
   "metadata": {},
   "source": [
    "### Why do we care? How to apply this to journalism\n",
    "\n",
    "These tools can help us analyze documents in large quantities. Let's apply this to the article about [Bruno, the thicc cat](https://www.buzzfeednews.com/article/juliareinstein/this-thicc-lazy-high-maintenance-incredibly-well-hydrated). \n",
    "\n",
    "Lets say our goal is to run an analysis of every word in our analysis and we want to know the following for each word:\n",
    "- what its name entity is\n",
    "- what its sentiment is\n",
    "\n",
    "For this exercise you will need to:\n",
    "- Create a word list (hint: look at last week!) ← you’ll do this alone\n",
    "- Create a new column for the name entity:\n",
    "  - Use the `.apply()` function to apply a custom function to the column containing the individual words\n",
    "- Create a column for the polarity score\n",
    "    - Use the `.apply()` function to apply a custom function to the column containing the individual words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc96cb-e997-4326-a2dd-eda839a2fdf5",
   "metadata": {},
   "source": [
    "##### Open the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d525c34-822b-43b7-89cd-b5df98397f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516af791-5cde-47b8-a9ed-9faa7a90c5a0",
   "metadata": {},
   "source": [
    "##### Turn text into nlp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ecc48b-e8c3-4486-8a9c-51c68aeb65f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca130ea4-c43d-4817-94d1-decd8da98b9f",
   "metadata": {},
   "source": [
    "##### Get sentinment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae04995-1fdf-4689-9f67-51c28b6e57d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cea090-46c4-432b-a27a-04b5090cfc5f",
   "metadata": {},
   "source": [
    "##### Turn article into array of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07b2e8-87e5-4106-8314-d3ea74fab498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075e99e-1fa9-46b9-8a69-1bc6d561a945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4a13f08-4d47-46d8-b3a3-165d83675e8c",
   "metadata": {},
   "source": [
    "##### Create a new column called \"ner\" and find the name entity for each word\n",
    "\n",
    "Make sure you apply a function to this column. \n",
    "\n",
    "Here's the syntax of a function: \n",
    "```\n",
    "def addnumbers(x):\n",
    "\tnew_number = 2 + x\n",
    "\treturn new_number\n",
    "```\n",
    "Here's how you apply it:\n",
    "```\n",
    "df[\"column\"].apply(addnumbers)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75041776-974c-4741-a072-7cc5cc1da946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244b2d5-8c84-4f6f-8fcd-141f245bd9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86033c5-1b13-4ecb-a074-6e7074bc5520",
   "metadata": {},
   "source": [
    "##### Summarize the dataframe of words via the \"ner\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ecfb6-cbd5-4426-9cea-f4d0b9876867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd833d-8874-4176-84d1-1bd40ab10bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e8e64-ac21-4f2b-91ea-5a5653e09711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4772104-a23f-4956-a13e-ca0bd4345a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
