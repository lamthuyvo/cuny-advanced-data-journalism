{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae37f5d1-e38d-409f-9ab6-b54556d79eb9",
   "metadata": {},
   "source": [
    "### Text cleaning and topic modeling\n",
    "\n",
    "This notebook is an example of topic modeling adapted from [this writeup](https://medium.com/@sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06).\n",
    "\n",
    "It performs the following tasks:\n",
    "\n",
    "- the first part of the notebook loads texts from a spreadsheet and turns them into one large corpuse\n",
    "- then we walk through various ways in which we can analyze and clean our corpus using spaCy (this includes taking out `stopwords` â€” words most often used in the English language and lemmatizing our corpus)\n",
    "- to better understand how a model works this notebook also explores some funcationalities of spaCy\n",
    "- the last parts of this notebook then make a simple topics model from the cleaned language data\n",
    "\n",
    "The libraries we will use are:\n",
    "- `pandas`: for reading in and exporting spreadsheets\n",
    "- `spacy`: a natural language processing library that contains various models trained on various languages\n",
    "- `gensim`: a library for topic modelling, document indexing and similarity retrieval with large corpora. In this case we will use it for topic modeling, the process of clustering words that seem to be used a lot in relation to one another. The algorithms built into genim that this notebook uses are called [Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2) and [Latent Semantic Analysis (LSA)](https://blog.marketmuse.com/glossary/latent-semantic-analysis-definition/).\n",
    "- `pyLDAvis`: a library that is capable of visualizing your topics clusters.\n",
    "\n",
    "Topic modeling is a form of unsupervised machine learning and can be really helpful in discovering topics in a large amount of text, especially if you're uncertain which topics might be buried in thousands or millions of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced40d95-a0fd-45bc-8e3d-018afc307fe6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "# for comprehension of language\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "# for topics modeling\n",
    "import gensim \n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel, LsiModel, HdpModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47309a2e-25da-4775-8139-1ef3b214fe5a",
   "metadata": {},
   "source": [
    "### Load spaCy's English language trained pipeline\n",
    "\n",
    "`A training pipeline typically reads training data from a feature store, performs model-dependent transformations, trains the model, and evaluates the model before the model is saved to a model registry.`\n",
    "\n",
    "You will need to download one of spaCy's models and can do so by typing this into a cell here:\n",
    "```\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535f8d12-1144-467a-bbaa-ef2700fe5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09006585-4b45-45c9-9578-02a9abe0d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the English language model \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18926fb2-aa30-4e55-8dcc-0e41fbed4a71",
   "metadata": {},
   "source": [
    "#### Stop words\n",
    "\n",
    "A lot of languages also contain 'stop words', words that are used very frequently and may not be useful when we're evaluating how often certain words may be used. spaCy has niftyfunctions that allow us to designate stop words for our analysis. \n",
    "\n",
    "For this purpose, we got stopwords [here](https://gist.github.com/sebleier/554280).\n",
    "\n",
    "First we need to open the text file adn then turn it into a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e9e53a-24fa-418f-b368-d494b6aa7e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 ['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'f', 'face', 'faces', 'fact', 'facts', 'far', 'felt', 'few', 'find', 'finds', 'first', 'for', 'four', 'from', 'full', 'fully', 'further', 'furthered', 'furthering', 'furthers', 'g', 'gave', 'general', 'generally', 'get', 'gets', 'give', 'given', 'gives', 'go', 'going', 'good', 'goods', 'got', 'great', 'greater', 'greatest', 'group', 'grouped', 'grouping', 'groups', 'h', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'herself', 'high', 'high', 'high', 'higher', 'highest', 'him', 'himself', 'his', 'how', 'however', 'i', 'if', 'important', 'in', 'interest', 'interested', 'interesting', 'interests', 'into', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kind', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', 'last', 'later', 'latest', 'least', 'less', 'let', 'lets', 'like', 'likely', 'long', 'longer', 'longest', 'm', 'made', 'make', 'making', 'man', 'many', 'may', 'me', 'member', 'members', 'men', 'might', 'more', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'my', 'myself', 'n', 'necessary', 'need', 'needed', 'needing', 'needs', 'never', 'new', 'new', 'newer', 'newest', 'next', 'no', 'nobody', 'non', 'noone', 'not', 'nothing', 'now', 'nowhere', 'number', 'numbers', 'o', 'of', 'off', 'often', 'old', 'older', 'oldest', 'on', 'once', 'one', 'only', 'open', 'opened', 'opening', 'opens', 'or', 'order', 'ordered', 'ordering', 'orders', 'other', 'others', 'our', 'out', 'over', 'p', 'part', 'parted', 'parting', 'parts', 'per', 'perhaps', 'place', 'places', 'point', 'pointed', 'pointing', 'points', 'possible', 'present', 'presented', 'presenting', 'presents', 'problem', 'problems', 'put', 'puts', 'q', 'quite', 'r', 'rather', 'really', 'right', 'right', 'room', 'rooms', 's', 'said', 'same', 'saw', 'say', 'says', 'second', 'seconds', 'see', 'seem', 'seemed', 'seeming', 'seems', 'sees', 'several', 'shall', 'she', 'should', 'show', 'showed', 'showing', 'shows', 'side', 'sides', 'since', 'small', 'smaller', 'smallest', 'so', 'some', 'somebody', 'someone', 'something', 'somewhere', 'state', 'states', 'still', 'still', 'such', 'sure', 't', 'take', 'taken', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'thoughts', 'three', 'through', 'thus', 'to', 'today', 'together', 'too', 'took', 'toward', 'turn', 'turned', 'turning', 'turns', 'two', 'u', 'under', 'until', 'up', 'upon', 'us', 'use', 'used', 'uses', 'v', 'very', 'w', 'want', 'wanted', 'wanting', 'wants', 'was', 'way', 'ways', 'we', 'well', 'wells', 'went', 'were', 'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'whose', 'why', 'will', 'with', 'within', 'without', 'work', 'worked', 'working', 'works', 'would', 'x', 'y', 'year', 'years', 'yet', 'you', 'young', 'younger', 'youngest', 'your', 'yours', 'z', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"../data/stopwords.txt\", \"r\") as file:\n",
    "    stop_words = file.read().split(\"\\n\")\n",
    "\n",
    "print(\n",
    "    len(stop_words), \n",
    "    stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343e2a1-7878-445a-b7e6-5a1addb27aa2",
   "metadata": {},
   "source": [
    "Next we use spaCy's model and define stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4113aa82-5a8a-40cc-9b80-a90236dc48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# starts a loop that iterates through each word in the stop_words list.\n",
    "for stopword in stop_words:\n",
    "    # This line retrieves the lexeme (the base or dictionary form of a word) from spaCy's vocabulary. \n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    # then we set `lexeme.is_stop = True`for each word, making every word a stop word in spaCy's vocabulary.\n",
    "    lexeme.is_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbdecb-b221-4888-b06a-0ae2b2f9f4ed",
   "metadata": {},
   "source": [
    "## Loading your text and making it a corpus\n",
    "\n",
    "#### First we need to load the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9bbc4d-422e-41ce-b170-1581aecd2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/@joolieannie_7404929915893681451.mp4</td>\n",
       "      <td>Ladies, let's be mindful when we use our phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/@joolieannie_1724362477829.mp4</td>\n",
       "      <td>give me one that's like the size of like a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/@joolieannie_1723610748575.mp4</td>\n",
       "      <td>You see how I do my makeup for work? Very dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/@joolieannie_1724324953244.mp4</td>\n",
       "      <td>Divas I'm in Los Angeles and Zillow needs my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/@joolieannie_1724362572281.mp4</td>\n",
       "      <td>Hi, Tvaz. Okay, so I've been going to the sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file_name  \\\n",
       "0  ../data/@joolieannie_7404929915893681451.mp4   \n",
       "1        ../data/@joolieannie_1724362477829.mp4   \n",
       "2        ../data/@joolieannie_1723610748575.mp4   \n",
       "3        ../data/@joolieannie_1724324953244.mp4   \n",
       "4        ../data/@joolieannie_1724362572281.mp4   \n",
       "\n",
       "                                          transcript  \n",
       "0   Ladies, let's be mindful when we use our phon...  \n",
       "1   give me one that's like the size of like a fi...  \n",
       "2   You see how I do my makeup for work? Very dem...  \n",
       "3   Divas I'm in Los Angeles and Zillow needs my ...  \n",
       "4   Hi, Tvaz. Okay, so I've been going to the sam...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load a spreadsheet with the text you want to analyze\n",
    "tiktok_influencer =  pd.read_csv(\"../data/transcripts_demure.csv\")\n",
    "\n",
    "print(len(tiktok_influencer))\n",
    "tiktok_influencer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509699aa-b11b-425a-b9b7-846f0372ba59",
   "metadata": {},
   "source": [
    "The next lines take all content from the `transcript` column, turn it into a list and then join it all with a space between each text. This creates one large corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8065628-6859-48ac-97c7-857d9840b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_list = tiktok_influencer[\"transcript\"].tolist()\n",
    " \n",
    "text = ' '.join(str(x) for x in transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e829d05-4fe3-4504-82b0-fb5c4eefc9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62b3040-370c-4d0f-94b9-44665c4c612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf634d9-48de-4743-9592-fa53a06d0710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff990b1-1877-49ca-b463-7d63aa5c8f2c",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "The next few lines 'normalize' the text and turns words into lemmas, get rid of stopwords and punctuation markers, and add lemmatized words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbcefef3-b7a5-4ee3-ab29-79b6cb3dcd07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lemma for the word   is  \n",
      "the lemma for the word Ladies is Ladies\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word let is let\n",
      "the lemma for the word 's is us\n",
      "the lemma for the word be is be\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word when is when\n",
      "the lemma for the word we is we\n",
      "the lemma for the word use is use\n",
      "the lemma for the word our is our\n",
      "the lemma for the word phones is phone\n",
      "the lemma for the word . is .\n",
      "the lemma for the word You is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word me is I\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word keep is keep\n",
      "the lemma for the word it is it\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cutesy is cutesy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word reply is reply\n",
      "the lemma for the word to is to\n",
      "the lemma for the word my is my\n",
      "the lemma for the word text is text\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word get is get\n",
      "the lemma for the word to is to\n",
      "the lemma for the word my is my\n",
      "the lemma for the word emails is email\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word a is a\n",
      "the lemma for the word few is few\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word picky is picky\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word picky is picky\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word flicky is flicky\n",
      "the lemma for the word flicky is flicky\n",
      "the lemma for the word flicky is flicky\n",
      "the lemma for the word 's is 's\n",
      "the lemma for the word . is .\n",
      "the lemma for the word And is and\n",
      "the lemma for the word that is that\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word why is why\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word a is a\n",
      "the lemma for the word Verizon is Verizon\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Verizon is Verizon\n",
      "the lemma for the word lets is let\n",
      "the lemma for the word me is I\n",
      "the lemma for the word trade is trade\n",
      "the lemma for the word in is in\n",
      "the lemma for the word a is a\n",
      "the lemma for the word musty is musty\n",
      "the lemma for the word diva is diva\n",
      "the lemma for the word for is for\n",
      "the lemma for the word a is a\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word diva is diva\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Verizon is Verizon\n",
      "the lemma for the word lets is let\n",
      "the lemma for the word anyone is anyone\n",
      "the lemma for the word trade is trade\n",
      "the lemma for the word in is in\n",
      "the lemma for the word a is a\n",
      "the lemma for the word crusty is crusty\n",
      "the lemma for the word phone is phone\n",
      "the lemma for the word for is for\n",
      "the lemma for the word a is a\n",
      "the lemma for the word new is new\n",
      "the lemma for the word one is one\n",
      "the lemma for the word . is .\n",
      "the lemma for the word We is we\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word have is have\n",
      "the lemma for the word a is a\n",
      "the lemma for the word crunchy is crunchy\n",
      "the lemma for the word phone is phone\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word we is we\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word do is do\n",
      "the lemma for the word a is a\n",
      "the lemma for the word crack is crack\n",
      "the lemma for the word screen is screen\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word typing is type\n",
      "the lemma for the word on is on\n",
      "the lemma for the word my is my\n",
      "the lemma for the word phone is phone\n",
      "the lemma for the word and is and\n",
      "the lemma for the word getting is get\n",
      "the lemma for the word cuts is cut\n",
      "the lemma for the word on is on\n",
      "the lemma for the word my is my\n",
      "the lemma for the word fingers is finger\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word charging is charge\n",
      "the lemma for the word my is my\n",
      "the lemma for the word phone is phone\n",
      "the lemma for the word and is and\n",
      "the lemma for the word it is it\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word really is really\n",
      "the lemma for the word what is what\n",
      "the lemma for the word I is I\n",
      "the lemma for the word will is will\n",
      "the lemma for the word go is go\n",
      "the lemma for the word and is and\n",
      "the lemma for the word crazy is crazy\n",
      "the lemma for the word on is on\n",
      "the lemma for the word me is I\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Thank is thank\n",
      "the lemma for the word you is you\n",
      "the lemma for the word . is .\n",
      "the lemma for the word You is you\n",
      "the lemma for the word thought is think\n",
      "the lemma for the word we is we\n",
      "the lemma for the word 'd is would\n",
      "the lemma for the word get is get\n",
      "the lemma for the word the is the\n",
      "the lemma for the word bag is bag\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word I is I\n",
      "the lemma for the word take is take\n",
      "the lemma for the word my is my\n",
      "the lemma for the word bag is bag\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cute is cute\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word respectful is respectful\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word staff is staff\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word do is do\n",
      "the lemma for the word crazy is crazy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word walk is walk\n",
      "the lemma for the word out is out\n",
      "the lemma for the word with is with\n",
      "the lemma for the word my is my\n",
      "the lemma for the word nice is nice\n",
      "the lemma for the word new is new\n",
      "the lemma for the word phone is phone\n",
      "the lemma for the word . is .\n",
      "the lemma for the word And is and\n",
      "the lemma for the word that is that\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word my is my\n",
      "the lemma for the word partner is partner\n",
      "the lemma for the word with is with\n",
      "the lemma for the word Verizon is Verizon\n",
      "the lemma for the word . is .\n",
      "the lemma for the word She is she\n",
      "the lemma for the word keeps is keep\n",
      "the lemma for the word her is her\n",
      "the lemma for the word elegant is elegant\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word she is she\n",
      "the lemma for the word keeps is keep\n",
      "the lemma for the word her is her\n",
      "the lemma for the word cutesy is cutesy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word she is she\n",
      "the lemma for the word keeps is keep\n",
      "the lemma for the word her is her\n",
      "the lemma for the word classy is classy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word She is she\n",
      "the lemma for the word does is do\n",
      "the lemma for the word red is red\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word she is she\n",
      "the lemma for the word does is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word do is do\n",
      "the lemma for the word hot is hot\n",
      "the lemma for the word pink is pink\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word she is she\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word crazy is crazy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word she is she\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word . is .\n",
      "the lemma for the word   is  \n",
      "the lemma for the word give is give\n",
      "the lemma for the word me is I\n",
      "the lemma for the word one is one\n",
      "the lemma for the word that is that\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word like is like\n",
      "the lemma for the word the is the\n",
      "the lemma for the word size is size\n",
      "the lemma for the word of is of\n",
      "the lemma for the word like is like\n",
      "the lemma for the word a is a\n",
      "the lemma for the word five is five\n",
      "the lemma for the word - is -\n",
      "the lemma for the word calibrate is calibrate\n",
      "the lemma for the word bucket is bucket\n",
      "the lemma for the word . is .\n",
      "the lemma for the word   is  \n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word my is my\n",
      "the lemma for the word makeup is makeup\n",
      "the lemma for the word for is for\n",
      "the lemma for the word work is work\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word Very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word very is very\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word come is come\n",
      "the lemma for the word to is to\n",
      "the lemma for the word work is work\n",
      "the lemma for the word with is with\n",
      "the lemma for the word a is a\n",
      "the lemma for the word green is green\n",
      "the lemma for the word cut is cut\n",
      "the lemma for the word crease is crease\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word look is look\n",
      "the lemma for the word like is like\n",
      "the lemma for the word a is a\n",
      "the lemma for the word clown is clown\n",
      "the lemma for the word when is when\n",
      "the lemma for the word I is I\n",
      "the lemma for the word go is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word work is work\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word do is do\n",
      "the lemma for the word too is too\n",
      "the lemma for the word much is much\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word while is while\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word at is at\n",
      "the lemma for the word work is work\n",
      "the lemma for the word . is .\n",
      "the lemma for the word See is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word I is I\n",
      "the lemma for the word look is look\n",
      "the lemma for the word very is very\n",
      "the lemma for the word presentable is presentable\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word The is the\n",
      "the lemma for the word way is way\n",
      "the lemma for the word I is I\n",
      "the lemma for the word came is come\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word interview is interview\n",
      "the lemma for the word is is be\n",
      "the lemma for the word the is the\n",
      "the lemma for the word way is way\n",
      "the lemma for the word I is I\n",
      "the lemma for the word go is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word job is job\n",
      "the lemma for the word . is .\n",
      "the lemma for the word A is a\n",
      "the lemma for the word lot is lot\n",
      "the lemma for the word of is of\n",
      "the lemma for the word you is you\n",
      "the lemma for the word girls is girl\n",
      "the lemma for the word go is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word interview is interview\n",
      "the lemma for the word looking is look\n",
      "the lemma for the word like is like\n",
      "the lemma for the word Marge is Marge\n",
      "the lemma for the word Simpson is Simpson\n",
      "the lemma for the word and is and\n",
      "the lemma for the word go is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word job is job\n",
      "the lemma for the word looking is look\n",
      "the lemma for the word like is like\n",
      "the lemma for the word Patty is Patty\n",
      "the lemma for the word and is and\n",
      "the lemma for the word Selma is Selma\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word not is not\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word modest is modest\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word . is .\n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word my is my\n",
      "the lemma for the word shirt is shirt\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word Only is only\n",
      "the lemma for the word a is a\n",
      "the lemma for the word little is little\n",
      "the lemma for the word cheaty is cheaty\n",
      "the lemma for the word out is out\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Not is not\n",
      "the lemma for the word my is my\n",
      "the lemma for the word chocho is chocho\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Be is be\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word of is of\n",
      "the lemma for the word why is why\n",
      "the lemma for the word they is they\n",
      "the lemma for the word hired is hire\n",
      "the lemma for the word you is you\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Here is here\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word your is your\n",
      "the lemma for the word reality is reality\n",
      "the lemma for the word check is check\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word Diva is Diva\n",
      "the lemma for the word . is .\n",
      "the lemma for the word What is what\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word the is the\n",
      "the lemma for the word name is name\n",
      "the lemma for the word you is you\n",
      "the lemma for the word 'd is would\n",
      "the lemma for the word like is like\n",
      "the lemma for the word me is I\n",
      "the lemma for the word to is to\n",
      "the lemma for the word make is make\n",
      "the lemma for the word it is it\n",
      "the lemma for the word out is out\n",
      "the lemma for the word to is to\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word   is  \n",
      "the lemma for the word Divas is Divas\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word in is in\n",
      "the lemma for the word Los is Los\n",
      "the lemma for the word Angeles is Angeles\n",
      "the lemma for the word and is and\n",
      "the lemma for the word Zillow is Zillow\n",
      "the lemma for the word needs is need\n",
      "the lemma for the word my is my\n",
      "the lemma for the word help is help\n",
      "the lemma for the word finding is find\n",
      "the lemma for the word out is out\n",
      "the lemma for the word which is which\n",
      "the lemma for the word of is of\n",
      "the lemma for the word these is these\n",
      "the lemma for the word houses is house\n",
      "the lemma for the word are is be\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word So is so\n",
      "the lemma for the word let is let\n",
      "the lemma for the word 's is us\n",
      "the lemma for the word find is find\n",
      "the lemma for the word out is out\n",
      "the lemma for the word and is and\n",
      "the lemma for the word be is be\n",
      "the lemma for the word cutesy is cutesy\n",
      "the lemma for the word together is together\n",
      "the lemma for the word . is .\n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word they is they\n",
      "the lemma for the word can is can\n",
      "the lemma for the word chose is chose\n",
      "the lemma for the word the is the\n",
      "the lemma for the word color is color\n",
      "the lemma for the word of is of\n",
      "the lemma for the word this is this\n",
      "the lemma for the word house is house\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word Very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word very is very\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word of is of\n",
      "the lemma for the word the is the\n",
      "the lemma for the word houses is house\n",
      "the lemma for the word there is there\n",
      "the lemma for the word is is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cutesy is cutesy\n",
      "the lemma for the word look is look\n",
      "the lemma for the word at is at\n",
      "the lemma for the word these is these\n",
      "the lemma for the word bushes is bush\n",
      "the lemma for the word OMG is OMG\n",
      "the lemma for the word divas is diva\n",
      "the lemma for the word a is a\n",
      "the lemma for the word real is real\n",
      "the lemma for the word diva is diva\n",
      "the lemma for the word lives is live\n",
      "the lemma for the word here is here\n",
      "the lemma for the word because is because\n",
      "the lemma for the word they is they\n",
      "the lemma for the word did is do\n",
      "the lemma for the word this is this\n",
      "the lemma for the word real is real\n",
      "the lemma for the word nice is nice\n",
      "the lemma for the word Real is real\n",
      "the lemma for the word elegant is elegant\n",
      "the lemma for the word very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word OMG is omg\n",
      "the lemma for the word She is she\n",
      "the lemma for the word is is be\n",
      "the lemma for the word the is the\n",
      "the lemma for the word queen is queen\n",
      "the lemma for the word of is of\n",
      "the lemma for the word the is the\n",
      "the lemma for the word murid is murid\n",
      "the lemma for the word They is they\n",
      "the lemma for the word 're is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word elegant is elegant\n",
      "the lemma for the word and is and\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word you is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word they is they\n",
      "the lemma for the word do is do\n",
      "the lemma for the word this is this\n",
      "the lemma for the word one is one\n",
      "the lemma for the word She is she\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cute is cute\n",
      "the lemma for the word . is .\n",
      "the lemma for the word She is she\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word beautiful is beautiful\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word but is but\n",
      "the lemma for the word she is she\n",
      "the lemma for the word hides is hide\n",
      "the lemma for the word it is it\n",
      "the lemma for the word from is from\n",
      "the lemma for the word the is the\n",
      "the lemma for the word world is world\n",
      "the lemma for the word because is because\n",
      "the lemma for the word she is she\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word like is like\n",
      "the lemma for the word how is how\n",
      "the lemma for the word they is they\n",
      "the lemma for the word do is do\n",
      "the lemma for the word the is the\n",
      "the lemma for the word tiles is tile\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word like is like\n",
      "the lemma for the word the is the\n",
      "the lemma for the word balcony is balcony\n",
      "the lemma for the word Not is not\n",
      "the lemma for the word divas is diva\n",
      "the lemma for the word this is this\n",
      "the lemma for the word house is house\n",
      "the lemma for the word is is be\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word this is this\n",
      "the lemma for the word is is be\n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word that is that\n",
      "the lemma for the word very is very\n",
      "the lemma for the word beautiful is beautiful\n",
      "the lemma for the word very is very\n",
      "the lemma for the word beautiful is beautiful\n",
      "the lemma for the word to is to\n",
      "the lemma for the word treat is treat\n",
      "the lemma for the word coming is come\n",
      "the lemma for the word out is out\n",
      "the lemma for the word of is of\n",
      "the lemma for the word the is the\n",
      "the lemma for the word house is house\n",
      "the lemma for the word to is to\n",
      "the lemma for the word giving is give\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cutesy is cutesy\n",
      "the lemma for the word very is very\n",
      "the lemma for the word sweet is sweet\n",
      "the lemma for the word I is I\n",
      "the lemma for the word mean is mean\n",
      "the lemma for the word if is if\n",
      "the lemma for the word I is I\n",
      "the lemma for the word had is have\n",
      "the lemma for the word this is this\n",
      "the lemma for the word house is house\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word parties is party\n",
      "the lemma for the word on is on\n",
      "the lemma for the word I is I\n",
      "the lemma for the word long is long\n",
      "the lemma for the word in is in\n",
      "the lemma for the word that is that\n",
      "the lemma for the word tree is tree\n",
      "the lemma for the word the is the\n",
      "the lemma for the word house is house\n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word elegant is elegant\n",
      "the lemma for the word this is this\n",
      "the lemma for the word is is be\n",
      "the lemma for the word   is  \n",
      "the lemma for the word Hi is Hi\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word Tvaz is Tvaz\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Okay is okay\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word so is so\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 've is have\n",
      "the lemma for the word been is be\n",
      "the lemma for the word going is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word the is the\n",
      "the lemma for the word same is same\n",
      "the lemma for the word nail is nail\n",
      "the lemma for the word salon is salon\n",
      "the lemma for the word for is for\n",
      "the lemma for the word like is like\n",
      "the lemma for the word forever is forever\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word but is but\n",
      "the lemma for the word I is I\n",
      "the lemma for the word just is just\n",
      "the lemma for the word think is think\n",
      "the lemma for the word it is it\n",
      "the lemma for the word turns is turn\n",
      "the lemma for the word like is like\n",
      "the lemma for the word mix is mix\n",
      "the lemma for the word it is it\n",
      "the lemma for the word up is up\n",
      "the lemma for the word I is I\n",
      "the lemma for the word want is want\n",
      "the lemma for the word to is to\n",
      "the lemma for the word get is get\n",
      "the lemma for the word my is my\n",
      "the lemma for the word nails is nail\n",
      "the lemma for the word done is do\n",
      "the lemma for the word tomorrow is tomorrow\n",
      "the lemma for the word morning is morning\n",
      "the lemma for the word Friday is Friday\n",
      "the lemma for the word morning is morning\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word that is that\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word tomorrow is tomorrow\n",
      "the lemma for the word morning is morning\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word looking is look\n",
      "the lemma for the word for is for\n",
      "the lemma for the word a is a\n",
      "the lemma for the word nail is nail\n",
      "the lemma for the word tech is tech\n",
      "the lemma for the word who is who\n",
      "the lemma for the word has is have\n",
      "the lemma for the word availability is availability\n",
      "the lemma for the word in is in\n",
      "the lemma for the word Chicago is Chicago\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'll is will\n",
      "the lemma for the word drive is drive\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'll is will\n",
      "the lemma for the word pay is pay\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word looking is look\n",
      "the lemma for the word for is for\n",
      "the lemma for the word anything is anything\n",
      "the lemma for the word for is for\n",
      "the lemma for the word free is free\n",
      "the lemma for the word I is I\n",
      "the lemma for the word just is just\n",
      "the lemma for the word need is need\n",
      "the lemma for the word guidance is guidance\n",
      "the lemma for the word to is to\n",
      "the lemma for the word like is like\n",
      "the lemma for the word a is a\n",
      "the lemma for the word good is good\n",
      "the lemma for the word nail is nail\n",
      "the lemma for the word tech is tech\n",
      "the lemma for the word who is who\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word like is like\n",
      "the lemma for the word hygienic is hygienic\n",
      "the lemma for the word Who is who\n",
      "the lemma for the word has is have\n",
      "the lemma for the word like is like\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word it is it\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word skillful is skillful\n",
      "the lemma for the word because is because\n",
      "the lemma for the word like is like\n",
      "the lemma for the word I is I\n",
      "the lemma for the word want is want\n",
      "the lemma for the word my is my\n",
      "the lemma for the word nails is nail\n",
      "the lemma for the word to is to\n",
      "the lemma for the word be is be\n",
      "the lemma for the word cute is cute\n",
      "the lemma for the word . is .\n",
      "the lemma for the word So is so\n",
      "the lemma for the word let is let\n",
      "the lemma for the word me is I\n",
      "the lemma for the word know is know\n",
      "the lemma for the word Diva is Diva\n",
      "the lemma for the word 's is 's\n",
      "the lemma for the word tag is tag\n",
      "the lemma for the word your is your\n",
      "the lemma for the word favorite is favorite\n",
      "the lemma for the word nail is nail\n",
      "the lemma for the word tech is tech\n",
      "the lemma for the word Um is Um\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word yeah is yeah\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word obviously is obviously\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word of is of\n",
      "the lemma for the word course is course\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word gon is go\n",
      "the lemma for the word na is to\n",
      "the lemma for the word tag is tag\n",
      "the lemma for the word them is they\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word gon is go\n",
      "the lemma for the word na is to\n",
      "the lemma for the word post is post\n",
      "the lemma for the word them is they\n",
      "the lemma for the word But is but\n",
      "the lemma for the word I is I\n",
      "the lemma for the word just is just\n",
      "the lemma for the word want is want\n",
      "the lemma for the word to is to\n",
      "the lemma for the word make is make\n",
      "the lemma for the word sure is sure\n",
      "the lemma for the word that is that\n",
      "the lemma for the word it is it\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word it is it\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word quality is quality\n",
      "the lemma for the word work is work\n",
      "the lemma for the word   is  \n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word I is I\n",
      "the lemma for the word lay is lie\n",
      "the lemma for the word in is in\n",
      "the lemma for the word bed is bed\n",
      "the lemma for the word and is and\n",
      "the lemma for the word I is I\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word a is a\n",
      "the lemma for the word glibadi is glibadi\n",
      "the lemma for the word on is on\n",
      "the lemma for the word Netflix is Netflix\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word I is I\n",
      "the lemma for the word keep is keep\n",
      "the lemma for the word it is it\n",
      "the lemma for the word real is real\n",
      "the lemma for the word simple is simple\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word an is an\n",
      "the lemma for the word ice is ice\n",
      "the lemma for the word - is -\n",
      "the lemma for the word water is water\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word my is my\n",
      "the lemma for the word fan is fan\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word like is like\n",
      "the lemma for the word an is an\n",
      "the lemma for the word ice is ice\n",
      "the lemma for the word - is -\n",
      "the lemma for the word prize is prize\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word keep is keep\n",
      "the lemma for the word it is it\n",
      "the lemma for the word very is very\n",
      "the lemma for the word to is to\n",
      "the lemma for the word me is I\n",
      "the lemma for the word or is or\n",
      "the lemma for the word very is very\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Let is let\n",
      "the lemma for the word 's is us\n",
      "the lemma for the word be is be\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word of is of\n",
      "the lemma for the word why is why\n",
      "the lemma for the word we is we\n",
      "the lemma for the word 're is be\n",
      "the lemma for the word watching is watch\n",
      "the lemma for the word a is a\n",
      "the lemma for the word glibadi is glibadi\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word bring is bring\n",
      "the lemma for the word Betty is Betty\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word bring is bring\n",
      "the lemma for the word Willa is Willa\n",
      "the lemma for the word Mina is Mina\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word keep is keep\n",
      "the lemma for the word it is it\n",
      "the lemma for the word real is real\n",
      "the lemma for the word cute is cute\n",
      "the lemma for the word - is -\n",
      "the lemma for the word seey is seey\n",
      "the lemma for the word when is when\n",
      "the lemma for the word I is I\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word my is my\n",
      "the lemma for the word ugly is ugly\n",
      "the lemma for the word beddy is beddy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word get is get\n",
      "the lemma for the word very is very\n",
      "the lemma for the word invested is invest\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word two is two\n",
      "the lemma for the word or is or\n",
      "the lemma for the word three is three\n",
      "the lemma for the word or is or\n",
      "the lemma for the word five is five\n",
      "the lemma for the word episodes is episode\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word get is get\n",
      "the lemma for the word braces is brace\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word get is get\n",
      "the lemma for the word bangs is bang\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word get is get\n",
      "the lemma for the word very is very\n",
      "the lemma for the word invested is invest\n",
      "the lemma for the word . is .\n",
      "the lemma for the word And is and\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word do is do\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word a is a\n",
      "the lemma for the word big is big\n",
      "the lemma for the word crazy is crazy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word let is let\n",
      "the lemma for the word me is I\n",
      "the lemma for the word eat is eat\n",
      "the lemma for the word something is something\n",
      "the lemma for the word wild is wild\n",
      "the lemma for the word like is like\n",
      "the lemma for the word you is you\n",
      "the lemma for the word girls is girl\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word a is a\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cute is cute\n",
      "the lemma for the word - is -\n",
      "the lemma for the word seey is seey\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word sweet is sweet\n",
      "the lemma for the word - is -\n",
      "the lemma for the word seey is seey\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word snack is snack\n",
      "the lemma for the word when is when\n",
      "the lemma for the word I is I\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word my is my\n",
      "the lemma for the word ugly is ugly\n",
      "the lemma for the word beddy is beddy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Something is something\n",
      "the lemma for the word very is very\n",
      "the lemma for the word simple is simple\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word nothing is nothing\n",
      "the lemma for the word crazy is crazy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Can is can\n",
      "the lemma for the word you is you\n",
      "the lemma for the word say is say\n",
      "the lemma for the word how is how\n",
      "the lemma for the word cozy is cozy\n",
      "the lemma for the word I is I\n",
      "the lemma for the word am is be\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word Very is very\n",
      "the lemma for the word cozy is cozy\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word you is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cozy is cozy\n",
      "the lemma for the word when is when\n",
      "the lemma for the word I is I\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word my is my\n",
      "the lemma for the word ugly is ugly\n",
      "the lemma for the word beddy is beddy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Let is let\n",
      "the lemma for the word 's is us\n",
      "the lemma for the word be is be\n",
      "the lemma for the word mindful is mindful\n",
      "the lemma for the word of is of\n",
      "the lemma for the word why is why\n",
      "the lemma for the word we is we\n",
      "the lemma for the word put is put\n",
      "the lemma for the word ugly is ugly\n",
      "the lemma for the word beddy is beddy\n",
      "the lemma for the word on is on\n",
      "the lemma for the word . is .\n",
      "the lemma for the word Willa is Willa\n",
      "the lemma for the word Mina is Mina\n",
      "the lemma for the word is is be\n",
      "the lemma for the word not is not\n",
      "the lemma for the word going is go\n",
      "the lemma for the word to is to\n",
      "the lemma for the word watch is watch\n",
      "the lemma for the word herself is herself\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word   is  \n",
      "the lemma for the word You is you\n",
      "the lemma for the word see is see\n",
      "the lemma for the word how is how\n",
      "the lemma for the word I is I\n",
      "the lemma for the word walk is walk\n",
      "the lemma for the word through is through\n",
      "the lemma for the word the is the\n",
      "the lemma for the word Wavuzva is Wavuzva\n",
      "the lemma for the word Hollywood is Hollywood\n",
      "the lemma for the word Hotel is Hotel\n",
      "the lemma for the word and is and\n",
      "the lemma for the word 9 is 9\n",
      "the lemma for the word am is am\n",
      "the lemma for the word ? is ?\n",
      "the lemma for the word I is I\n",
      "the lemma for the word do is do\n",
      "the lemma for the word n't is not\n",
      "the lemma for the word make is make\n",
      "the lemma for the word noise is noise\n",
      "the lemma for the word like is like\n",
      "the lemma for the word you is you\n",
      "the lemma for the word girls is girl\n",
      "the lemma for the word . is .\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word demure is demure\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word 'm is be\n",
      "the lemma for the word very is very\n",
      "the lemma for the word cheesy is cheesy\n",
      "the lemma for the word . is .\n",
      "the lemma for the word You is you\n",
      "the lemma for the word know is know\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word I is I\n",
      "the lemma for the word hit is hit\n",
      "the lemma for the word the is the\n",
      "the lemma for the word blinker is blinker\n",
      "the lemma for the word four is four\n",
      "the lemma for the word times is time\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word and is and\n",
      "the lemma for the word I is I\n",
      "the lemma for the word said is say\n",
      "the lemma for the word , is ,\n",
      "the lemma for the word it is it\n",
      "the lemma for the word 's is be\n",
      "the lemma for the word a is a\n",
      "the lemma for the word wild is wild\n",
      "the lemma for the word like is like\n",
      "the lemma for the word you is you\n",
      "the lemma for the word girls is girl\n",
      "the lemma for the word . is .\n"
     ]
    }
   ],
   "source": [
    "# here's a demo of us cycling through the \n",
    "for word in doc:\n",
    "    print(f\"the lemma for the word {word} is {word.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b42250-57a4-458b-9de2-21dbaba84e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95fbb2dd-5088-4da9-8cdf-5ebaa3c1a100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ladies'] 279\n"
     ]
    }
   ],
   "source": [
    "# We add some words to the stop word list\n",
    "\n",
    "#let's create some empty arrays. \n",
    "# texts will hold all our words that we will use for our topic model\n",
    "texts = []\n",
    "# is a temporary array that we will use to store the lemma-version of a word\n",
    "article = []\n",
    "\n",
    "for word in doc:\n",
    "    if word.text != '\\n' and not word.is_stop and not word.is_punct and not word.like_num:\n",
    "        article.append(word.lemma_)\n",
    "        texts.append(article)\n",
    "        article = []\n",
    "        \n",
    "print(texts[1], len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aeffef5-79c4-4499-840e-347c46c66ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' '],\n",
       " ['Ladies'],\n",
       " ['mindful'],\n",
       " ['phone'],\n",
       " ['cutesy'],\n",
       " ['demure'],\n",
       " ['reply'],\n",
       " ['text'],\n",
       " ['email'],\n",
       " ['picky'],\n",
       " ['picky'],\n",
       " ['flicky'],\n",
       " ['flicky'],\n",
       " ['flicky'],\n",
       " ['Verizon'],\n",
       " ['Verizon'],\n",
       " ['trade'],\n",
       " ['musty'],\n",
       " ['diva'],\n",
       " ['demure'],\n",
       " ['diva'],\n",
       " ['Verizon'],\n",
       " ['trade'],\n",
       " ['crusty'],\n",
       " ['phone'],\n",
       " ['crunchy'],\n",
       " ['phone'],\n",
       " ['crack'],\n",
       " ['screen'],\n",
       " ['type'],\n",
       " ['phone'],\n",
       " ['get'],\n",
       " ['cut'],\n",
       " ['finger'],\n",
       " ['charge'],\n",
       " ['phone'],\n",
       " ['crazy'],\n",
       " ['thank'],\n",
       " ['bag'],\n",
       " ['bag'],\n",
       " ['cute'],\n",
       " ['respectful'],\n",
       " ['staff'],\n",
       " ['crazy'],\n",
       " ['walk'],\n",
       " ['nice'],\n",
       " ['phone'],\n",
       " ['partner'],\n",
       " ['Verizon'],\n",
       " ['elegant'],\n",
       " ['cutesy'],\n",
       " ['classy'],\n",
       " ['red'],\n",
       " ['hot'],\n",
       " ['pink'],\n",
       " ['crazy'],\n",
       " ['demure'],\n",
       " [' '],\n",
       " ['size'],\n",
       " ['calibrate'],\n",
       " ['bucket'],\n",
       " [' '],\n",
       " ['makeup'],\n",
       " ['demure'],\n",
       " ['mindful'],\n",
       " ['green'],\n",
       " ['cut'],\n",
       " ['crease'],\n",
       " ['look'],\n",
       " ['clown'],\n",
       " ['mindful'],\n",
       " ['look'],\n",
       " ['presentable'],\n",
       " ['interview'],\n",
       " ['job'],\n",
       " ['lot'],\n",
       " ['girl'],\n",
       " ['interview'],\n",
       " ['look'],\n",
       " ['Marge'],\n",
       " ['Simpson'],\n",
       " ['job'],\n",
       " ['look'],\n",
       " ['Patty'],\n",
       " ['Selma'],\n",
       " ['demure'],\n",
       " ['modest'],\n",
       " ['mindful'],\n",
       " ['shirt'],\n",
       " ['little'],\n",
       " ['cheaty'],\n",
       " ['chocho'],\n",
       " ['mindful'],\n",
       " ['hire'],\n",
       " ['reality'],\n",
       " ['check'],\n",
       " ['Diva'],\n",
       " [' '],\n",
       " ['Divas'],\n",
       " ['Los'],\n",
       " ['Angeles'],\n",
       " ['Zillow'],\n",
       " ['help'],\n",
       " ['find'],\n",
       " ['house'],\n",
       " ['demure'],\n",
       " ['cutesy'],\n",
       " ['chose'],\n",
       " ['color'],\n",
       " ['house'],\n",
       " ['demure'],\n",
       " ['mindful'],\n",
       " ['house'],\n",
       " ['cutesy'],\n",
       " ['look'],\n",
       " ['bush'],\n",
       " ['OMG'],\n",
       " ['diva'],\n",
       " ['real'],\n",
       " ['diva'],\n",
       " ['live'],\n",
       " ['real'],\n",
       " ['nice'],\n",
       " ['real'],\n",
       " ['elegant'],\n",
       " ['demure'],\n",
       " ['omg'],\n",
       " ['queen'],\n",
       " ['murid'],\n",
       " ['elegant'],\n",
       " ['demure'],\n",
       " ['cute'],\n",
       " ['beautiful'],\n",
       " ['hide'],\n",
       " ['world'],\n",
       " ['mindful'],\n",
       " ['tile'],\n",
       " ['balcony'],\n",
       " ['diva'],\n",
       " ['house'],\n",
       " ['demure'],\n",
       " ['beautiful'],\n",
       " ['beautiful'],\n",
       " ['treat'],\n",
       " ['come'],\n",
       " ['house'],\n",
       " ['give'],\n",
       " ['cutesy'],\n",
       " ['sweet'],\n",
       " ['mean'],\n",
       " ['house'],\n",
       " ['demure'],\n",
       " ['party'],\n",
       " ['tree'],\n",
       " ['house'],\n",
       " ['elegant'],\n",
       " [' '],\n",
       " ['Hi'],\n",
       " ['Tvaz'],\n",
       " ['okay'],\n",
       " ['nail'],\n",
       " ['salon'],\n",
       " ['forever'],\n",
       " ['mix'],\n",
       " ['nail'],\n",
       " ['tomorrow'],\n",
       " ['morning'],\n",
       " ['Friday'],\n",
       " ['morning'],\n",
       " ['tomorrow'],\n",
       " ['morning'],\n",
       " ['look'],\n",
       " ['nail'],\n",
       " ['tech'],\n",
       " ['availability'],\n",
       " ['Chicago'],\n",
       " ['drive'],\n",
       " ['pay'],\n",
       " ['look'],\n",
       " ['free'],\n",
       " ['guidance'],\n",
       " ['nail'],\n",
       " ['tech'],\n",
       " ['hygienic'],\n",
       " ['skillful'],\n",
       " ['nail'],\n",
       " ['cute'],\n",
       " ['Diva'],\n",
       " ['tag'],\n",
       " ['favorite'],\n",
       " ['nail'],\n",
       " ['tech'],\n",
       " ['Um'],\n",
       " ['yeah'],\n",
       " ['obviously'],\n",
       " ['course'],\n",
       " ['go'],\n",
       " ['to'],\n",
       " ['tag'],\n",
       " ['go'],\n",
       " ['to'],\n",
       " ['post'],\n",
       " ['quality'],\n",
       " [' '],\n",
       " ['lie'],\n",
       " ['bed'],\n",
       " ['watch'],\n",
       " ['glibadi'],\n",
       " ['Netflix'],\n",
       " ['real'],\n",
       " ['simple'],\n",
       " ['ice'],\n",
       " ['water'],\n",
       " ['fan'],\n",
       " ['ice'],\n",
       " ['prize'],\n",
       " ['mindful'],\n",
       " ['let'],\n",
       " ['mindful'],\n",
       " ['watch'],\n",
       " ['glibadi'],\n",
       " ['bring'],\n",
       " ['Betty'],\n",
       " ['bring'],\n",
       " ['Willa'],\n",
       " ['Mina'],\n",
       " ['real'],\n",
       " ['cute'],\n",
       " ['seey'],\n",
       " ['watch'],\n",
       " ['ugly'],\n",
       " ['beddy'],\n",
       " ['invest'],\n",
       " ['watch'],\n",
       " ['episode'],\n",
       " ['brace'],\n",
       " ['bang'],\n",
       " ['invest'],\n",
       " ['crazy'],\n",
       " ['eat'],\n",
       " ['wild'],\n",
       " ['girl'],\n",
       " ['cute'],\n",
       " ['seey'],\n",
       " ['sweet'],\n",
       " ['seey'],\n",
       " ['snack'],\n",
       " ['watch'],\n",
       " ['ugly'],\n",
       " ['beddy'],\n",
       " ['simple'],\n",
       " ['crazy'],\n",
       " ['cozy'],\n",
       " ['cozy'],\n",
       " ['cozy'],\n",
       " ['watch'],\n",
       " ['ugly'],\n",
       " ['beddy'],\n",
       " ['let'],\n",
       " ['mindful'],\n",
       " ['ugly'],\n",
       " ['beddy'],\n",
       " ['Willa'],\n",
       " ['Mina'],\n",
       " ['watch'],\n",
       " [' '],\n",
       " ['walk'],\n",
       " ['Wavuzva'],\n",
       " ['Hollywood'],\n",
       " ['Hotel'],\n",
       " ['noise'],\n",
       " ['girl'],\n",
       " ['demure'],\n",
       " ['cheesy'],\n",
       " ['hit'],\n",
       " ['blinker'],\n",
       " ['time'],\n",
       " ['wild'],\n",
       " ['girl']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffba45-d6fa-44e3-915c-deb07ac9d0fb",
   "metadata": {},
   "source": [
    "In the next lines we turn these cleaned texts into a bag-of-words format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe4a03a-cabc-4ea1-b663-7a96dfbb53bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary() to map each unique word to a unique integer ID\n",
    "dictionary = Dictionary(texts)\n",
    "# this line creates a corpus and converts a single document (a list of words) into a bag-of-words format\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce230e8-c30b-43d8-93ef-8f68e9cda7ab",
   "metadata": {},
   "source": [
    "## Different Kinds of Topic Modeling \n",
    "Topic Modeling refers to the probabilistic modeling of text documents as topics. Gensim is one of the most popular libraries to perform such modeling.\n",
    "\n",
    "#### LSI â€” Latent Semantic Indexing\n",
    "One of the methods available in gensim is called LSI, which stands for Latent Semantic Indexing. LSI aims to find hidden (latent) relationships between words and concepts in a collection of documents. The assumption here is words that are used in similar contexts tend to have similar meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cbbb000-7349-4ed7-8403-3e35ac591b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '1.000*\"demure\" + -0.000*\"Um\" + 0.000*\"thank\" + -0.000*\"chocho\" + 0.000*\"hide\" + 0.000*\"episode\" + -0.000*\"clown\" + -0.000*\"reply\" + -0.000*\"mix\" + -0.000*\"text\"'),\n",
       " (1,\n",
       "  '1.000*\"mindful\" + 0.001*\"color\" + -0.001*\"size\" + -0.001*\"staff\" + 0.001*\"omg\" + -0.001*\"OMG\" + 0.001*\"reply\" + 0.001*\"Los\" + 0.001*\"Friday\" + -0.001*\"reality\"'),\n",
       " (2,\n",
       "  '-0.687*\"look\" + 0.546*\"watch\" + -0.386*\"house\" + 0.285*\" \" + 0.001*\"partner\" + 0.001*\"snack\" + 0.001*\"water\" + 0.001*\"Los\" + 0.001*\"come\" + -0.001*\"cheaty\"'),\n",
       " (3,\n",
       "  '-0.650*\"look\" + 0.612*\"house\" + -0.419*\" \" + -0.167*\"watch\" + -0.001*\"hygienic\" + 0.001*\"Betty\" + 0.001*\"Selma\" + 0.001*\"obviously\" + 0.001*\"crusty\" + -0.001*\"little\"'),\n",
       " (4,\n",
       "  '-0.676*\"house\" + -0.656*\" \" + -0.306*\"watch\" + -0.135*\"look\" + 0.002*\"respectful\" + -0.002*\"reality\" + 0.002*\"free\" + 0.002*\"Hi\" + 0.002*\"bed\" + 0.002*\"Zillow\"'),\n",
       " (5,\n",
       "  '0.762*\"watch\" + -0.559*\" \" + 0.296*\"look\" + 0.139*\"house\" + 0.002*\"musty\" + -0.002*\"give\" + -0.002*\"mean\" + 0.002*\"Marge\" + -0.002*\"crunchy\" + 0.002*\"Patty\"'),\n",
       " (6,\n",
       "  '0.854*\"phone\" + -0.521*\"nail\" + -0.002*\"pay\" + 0.002*\"come\" + -0.002*\"Friday\" + 0.002*\"Hi\" + 0.002*\"screen\" + 0.002*\"mean\" + 0.002*\"prize\" + -0.002*\"Patty\"'),\n",
       " (7,\n",
       "  '0.854*\"nail\" + 0.521*\"phone\" + 0.002*\"availability\" + 0.002*\"balcony\" + 0.002*\"reply\" + 0.002*\"Marge\" + 0.002*\"prize\" + -0.002*\"water\" + -0.002*\"murid\" + -0.002*\"OMG\"'),\n",
       " (8,\n",
       "  '0.834*\"crazy\" + 0.360*\"diva\" + -0.357*\"cutesy\" + -0.186*\"cute\" + -0.113*\"real\" + -0.004*\"presentable\" + -0.004*\"Hollywood\" + -0.003*\"hide\" + 0.003*\"size\" + -0.003*\"classy\"'),\n",
       " (9,\n",
       "  '-0.745*\"diva\" + -0.595*\"cute\" + 0.224*\"real\" + 0.184*\"crazy\" + -0.083*\"cutesy\" + -0.004*\"charge\" + 0.004*\"episode\" + 0.003*\"salon\" + 0.003*\"bush\" + -0.003*\"color\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "lsi_model.show_topics(num_topics=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fe9a6-42b5-45cb-91c9-14f699317b78",
   "metadata": {},
   "source": [
    "#### HDP â€” Hierarchical Dirichlet Process\n",
    "HDP, the Hierarchical Dirichlet Process is an unsupervised Topic Model which figures out the number of topics on its own. HPD assumes that documents are mixtures of topics, and topics are mixtures of words, but it doesn't limit the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea15908-f386-4187-a846-182ab2ec4e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.039*green + 0.035*Patty + 0.025*go + 0.024*bring + 0.024*Verizon + 0.023*quality + 0.022*hygienic + 0.022*phone + 0.021*respectful + 0.021*get + 0.018*Wavuzva + 0.018*queen + 0.018*obviously + 0.017*Hotel + 0.017*sweet + 0.017*classy + 0.016*hide + 0.014*guidance + 0.013*tree + 0.013*post'),\n",
       " (1,\n",
       "  '0.043*okay + 0.038*forever + 0.026*check + 0.023*Tvaz + 0.020*little + 0.019*help + 0.018*Los + 0.017*Simpson + 0.017*Hotel + 0.016*shirt + 0.015*yeah + 0.015*Selma + 0.015*partner + 0.014*salon + 0.014*email + 0.014*tile + 0.013*nail + 0.013*omg + 0.013*world + 0.013*cheesy'),\n",
       " (2,\n",
       "  '0.028*guidance + 0.028*hire + 0.027*size + 0.027*Tvaz + 0.025*Simpson + 0.022*favorite + 0.020*crusty + 0.019*invest + 0.018*Hollywood + 0.018*red + 0.017*check + 0.016*Marge + 0.015*demure + 0.015*lie + 0.015*bed + 0.015*wild + 0.014*flicky + 0.013*bang + 0.013*omg + 0.013*staff'),\n",
       " (3,\n",
       "  '0.035*color + 0.027*simple + 0.024*charge + 0.024*Netflix + 0.023*go + 0.020*tomorrow + 0.019*Betty + 0.019*tile + 0.019*post + 0.019*eat + 0.018*hide + 0.017*reply + 0.016*Friday + 0.015*wild + 0.015*ice + 0.014*yeah + 0.014*trade + 0.013*balcony + 0.013*blinker + 0.013*cheaty'),\n",
       " (4,\n",
       "  '0.030*Mina + 0.029*post + 0.027*Selma + 0.027*clown + 0.022*treat + 0.019*cheesy + 0.019*shirt + 0.019*crusty + 0.017*bed + 0.017*ice + 0.016*respectful + 0.016*simple + 0.016*color + 0.015*seey + 0.014*cozy + 0.014*Hotel + 0.014*tomorrow + 0.013*makeup + 0.013*Zillow + 0.013*presentable')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdp_model = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdp_model.show_topics()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eff84d-1d3c-4a10-85a5-7b792116f635",
   "metadata": {},
   "source": [
    "#### LDA â€” Latent Dirichlet Allocation\n",
    "LDA or Latent Dirichlet Allocation is arguably the most famous Topic Modeling algorithm out there. Out here we create a simple Topic Model with 5 topics. The LDA algorithm assumes that each document is a mixture of topics, and each topic is a mixture of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24830a4c-8ed6-498d-affc-81be19401d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.051*\"Verizon\" + 0.039*\"diva\" + 0.039*\"tech\" + 0.039*\"real\" + 0.039*\"elegant\" + 0.039*\"beautiful\" + 0.039*\"seey\" + 0.027*\"simple\" + 0.027*\"nice\" + 0.015*\"nail\"'),\n",
       " (1,\n",
       "  '0.091*\"house\" + 0.041*\"demure\" + 0.041*\"watch\" + 0.040*\"beddy\" + 0.028*\"diva\" + 0.028*\"nail\" + 0.028*\"sweet\" + 0.028*\"picky\" + 0.028*\"glibadi\" + 0.015*\"to\"'),\n",
       " (2,\n",
       "  '0.091*\"demure\" + 0.071*\" \" + 0.052*\"cute\" + 0.032*\"ugly\" + 0.022*\"cut\" + 0.022*\"let\" + 0.022*\"cozy\" + 0.022*\"Willa\" + 0.022*\"walk\" + 0.022*\"Diva\"'),\n",
       " (3,\n",
       "  '0.052*\"watch\" + 0.040*\"flicky\" + 0.040*\"cutesy\" + 0.028*\"nail\" + 0.028*\"real\" + 0.028*\"invest\" + 0.027*\"wild\" + 0.016*\"look\" + 0.015*\"girl\" + 0.015*\"crazy\"'),\n",
       " (4,\n",
       "  '0.100*\"mindful\" + 0.061*\"look\" + 0.061*\"phone\" + 0.041*\"crazy\" + 0.032*\"morning\" + 0.031*\"girl\" + 0.022*\"bring\" + 0.022*\"go\" + 0.022*\"bag\" + 0.022*\"tag\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = LdaModel(corpus=corpus, num_topics=5, id2word=dictionary)\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f3d12-9624-4700-8662-a43d0305dfca",
   "metadata": {},
   "source": [
    "## Visualizing Topics with pyLDAvis\n",
    "pyLDAvis is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization.\n",
    "\n",
    "The visualization is intended to be used within an IPython notebook but can also be saved to a stand-alone HTML file for easy sharing.\n",
    "\n",
    "**Note: If you have issues running the `pyLDAvis.gensim_modeles.prepare()` function, you may need to walk yourself through [these fixes](https://docs.google.com/document/d/1XOz5fJdHR754SHkMIrqCxkgD2yGHhBlueK4EcbaNwII/edit?usp=sharing).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6359801b-6e47-4fa3-9026-a1a82b590233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for visualizations\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dfc7dba-559b-4ced-9889-204b5df135da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e9a870-2e09-45cb-8af5-cd4029c36d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, \"../output/topics_modeling_demure.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "697e38eb-c485-4434-83e3-1102152c24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5fc1b-6e06-4ffc-b832-e1f045aedc18",
   "metadata": {},
   "source": [
    "## Word count\n",
    "For good measure, we can also use this space to make a word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da9a2a3b-742c-40af-85ff-fe4f0133a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ladies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mindful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cutesy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "0         \n",
       "1   Ladies\n",
       "2  mindful\n",
       "3    phone\n",
       "4   cutesy"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_influencer = pd.DataFrame(texts)\n",
    "print(len(words_influencer))\n",
    "words_influencer.columns = [\"word\"]\n",
    "words_influencer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19873bb5-106f-4347-9f3b-8e79c4fde9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "demure     12\n",
       "mindful    10\n",
       "            7\n",
       "look        7\n",
       "house       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tally = words_influencer[\"word\"].value_counts()\n",
    "word_tally.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b27d82c3-8481-4e42-a0c6-4d1ac113d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tally.to_csv(\"../output/word_tally_demure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f02bd-e91c-4ac8-ac0f-b2be718adca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f088c00-fbde-45b5-a621-4a331db314a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
