{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92eb472d-9fc3-42dc-b111-cc7bd41f985e",
   "metadata": {},
   "source": [
    "### Transcription using whisper\n",
    "\n",
    "This script uses OpenAI's whisper to auto translate videos. \n",
    "\n",
    "For this script we need these libraries:\n",
    "- json: a library that knows how to read json data formats since whisper transcribes audio into the json format\n",
    "- glob: a library that allows you to read file directories on your computer\n",
    "- pandas: our trusted data analysis library\n",
    "- whisper: OpenAI's open sourced [`whisper`](https://github.com/openai/whisper) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40ef2cf-af91-4458-8f6d-9280ff36041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f81933-9d8b-4a58-9ef0-fe7c4e4c2041",
   "metadata": {},
   "source": [
    "Using glob we find every video in the data directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb922660-2496-4a88-8216-84ac2e190f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"../data/\"\n",
    "paths  = glob.glob(base+\"*.mp4\")\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621069a-75eb-4161-8c1f-47b8ab64193b",
   "metadata": {},
   "source": [
    "Load OpenAI's model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed6d5d9-ece4-4ed9-91bb-a075ab27e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = whisper.load_model(\"base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80196d-7d5c-42dd-92c4-8cf3f65edca8",
   "metadata": {},
   "source": [
    "In the next cells we first write a few lines to transcribe each video. In a later version of the code we add these transcripts into an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5479b01-bfea-466e-9cc3-fcba4a1665e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ladies, let's be mindful when we use our phones. You know me, I keep it very cutesy, very demure. I reply to my text, I get to my emails, I do a few, you know, picky, picky, flicky flicky flicky's. And that's why I'm a Verizon. Verizon lets me trade in a musty diva for a demure diva. Verizon lets anyone trade in a crusty phone for a new one. We don't have a crunchy phone, we don't do a crack screen. I'm not typing on my phone and getting cuts on my fingers. I'm not charging my phone and it's really what I will go and crazy on me. Thank you. You thought we'd get the bag? I take my bag, I'm very cute. I'm very respectful to the staff. I don't do crazy, I walk out with my nice new phone. And that's my partner with Verizon. She keeps her elegant, she keeps her cutesy, she keeps her classy. She does red, she doesn't do hot pink, she's not crazy, she's very demure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " give me one that's like the size of like a five-calibrate bucket.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You see how I do my makeup for work? Very demure, very mindful. I don't come to work with a green cut crease. Don't look like a clown when I go to work. I don't do too much. I'm very mindful while I'm at work. See how I look very presentable? The way I came to the interview is the way I go to the job. A lot of you girls go to the interview looking like Marge Simpson and go to the job looking like Patty and Selma, not demure. I'm very modest. I'm very mindful. You see my shirt? Only a little cheaty out. Not my chocho. Be mindful of why they hired you. Here's your reality check, Diva. What's the name you'd like me to make it out to?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Divas I'm in Los Angeles and Zillow needs my help finding out which of these houses are demure So let's find out and be cutesy together. You see how they can chose the color of this house? Very demure very mindful of the houses there is very cutesy look at these bushes OMG divas a real diva lives here because they did this real nice Real elegant very demure OMG She is the queen of the murid They're very elegant and demure you see how they do this one She's very cute. She's beautiful, but she hides it from the world because she's mindful. I like how they do the tiles. I like the balcony Not divas this house is demure this is You see that very beautiful very beautiful to treat coming out of the house to giving very cutesy very sweet I mean if I had this house demure parties on I long in that tree the house You see how elegant this is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi, Tvaz. Okay, so I've been going to the same nail salon for like forever, but I just think it turns like mix it up I want to get my nails done tomorrow morning Friday morning, that's tomorrow morning I'm looking for a nail tech who has availability in Chicago. I'll drive. I'll pay. I'm not looking for anything for free I just need guidance to like a good nail tech who's like hygienic Who has like you know, it's skillful because like I want my nails to be cute. So let me know Diva's tag your favorite nail tech Um, yeah, you know, obviously, of course I'm gonna tag them. I'm gonna post them But I just want to make sure that it's not you know, it's quality work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You see how I lay in bed and I watch a glibadi on Netflix? I keep it real simple. I do an ice-water, I do my fan, I like an ice-prize, I keep it very to me or very mindful. Let's be mindful of why we're watching a glibadi. I bring Betty, I bring Willa Mina. I keep it real cute-seey when I watch my ugly beddy. I get very invested, I watch two or three or five episodes, I get braces, I get bangs, I get very invested. And I don't do, you know, a big crazy, let me eat something wild like you girls. I do a very cute-seey, sweet-seey, you know, snack when I watch my ugly beddy. Something very simple, nothing crazy. Can you say how cozy I am? Very cozy, you know, I'm very cozy when I watch my ugly beddy. Let's be mindful of why we put ugly beddy on. Willa Mina is not going to watch herself,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You see how I walk through the Wavuzva Hollywood Hotel and 9am? I don't make noise like you girls. I'm very demure, I'm very cheesy. You know, I hit the blinker four times, and I said, it's a wild like you girls.\n"
     ]
    }
   ],
   "source": [
    "for path in paths: \n",
    "    result = model.transcribe(path,  language=\"en\")\n",
    "    print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e8eecf-9a9a-4560-8f73-61dbc84a6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/lamthuyvo/Dropbox/teaching/CUNY/cuny-advanced-data-journalism/exercise-files/machine-learning/auto-transcription/venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for path in paths: \n",
    "    result = model.transcribe(path,  language=\"en\")\n",
    "    row = {\n",
    "            \"file_name\":path,\n",
    "            \"transcript\": result[\"text\"]\n",
    "          }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc2de3-bdd3-4a9f-bd92-36b5035165a4",
   "metadata": {},
   "source": [
    "Now that we have the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04985c43-7b81-491d-9817-e7adbe343a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee7089b-8f15-4025-8f44-f6ca50fbc996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/@joolieannie_7404929915893681451.mp4</td>\n",
       "      <td>Ladies, let's be mindful when we use our phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/@joolieannie_1724362477829.mp4</td>\n",
       "      <td>give me one that's like the size of like a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/@joolieannie_1723610748575.mp4</td>\n",
       "      <td>You see how I do my makeup for work? Very dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/@joolieannie_1724324953244.mp4</td>\n",
       "      <td>Divas I'm in Los Angeles and Zillow needs my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/@joolieannie_1724362572281.mp4</td>\n",
       "      <td>Hi, Tvaz. Okay, so I've been going to the sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file_name  \\\n",
       "0  ../data/@joolieannie_7404929915893681451.mp4   \n",
       "1        ../data/@joolieannie_1724362477829.mp4   \n",
       "2        ../data/@joolieannie_1723610748575.mp4   \n",
       "3        ../data/@joolieannie_1724324953244.mp4   \n",
       "4        ../data/@joolieannie_1724362572281.mp4   \n",
       "\n",
       "                                          transcript  \n",
       "0   Ladies, let's be mindful when we use our phon...  \n",
       "1   give me one that's like the size of like a fi...  \n",
       "2   You see how I do my makeup for work? Very dem...  \n",
       "3   Divas I'm in Los Angeles and Zillow needs my ...  \n",
       "4   Hi, Tvaz. Okay, so I've been going to the sam...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63171918-0d61-4049-b538-c2836f2dc9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcripts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794df141-faad-4be5-ab75-d8f9874151e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts.to_csv(\"../output/transcripts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9cde8-0b60-471e-aae1-b62a25edc88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
