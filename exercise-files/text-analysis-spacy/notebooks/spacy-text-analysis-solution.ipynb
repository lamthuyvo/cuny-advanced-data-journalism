{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample text analysis using spacy\n",
    "\n",
    "Spacy is a library that can assist you in doing linguistic analyses. \n",
    "\n",
    "To install and use the Englis-language version of spacy you should run these commands in your virtual environment:\n",
    "`pip3 install spacy`\n",
    "`python3 -m spacy download en_core_web_sm`\n",
    "We will be importing the `text.txt` file in our `data` folder. It contains a sample article about a very special [cat](https://www.buzzfeednews.com/article/juliareinstein/this-thicc-lazy-high-maintenance-incredibly-well-hydrated/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# opens the text file and turns it into a string\n",
    "text = open(\"../data/text.txt\",\"r+\").read()\n",
    "len(text) # this returns the length of characters and spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn the string into a corpus for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "len(doc) # this returns the tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document can act like a list of words. To access each word or 'token' we can use the built in function `.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "Bruno\n",
      ",\n",
      "and\n",
      "he\n",
      "’s\n",
      "a\n",
      "25\n",
      "-\n",
      "pound\n",
      "cat\n",
      "who\n",
      "’s\n",
      "currently\n",
      "up\n",
      "for\n",
      "adoption\n",
      "at\n",
      "the\n",
      "Wright\n",
      "-\n",
      "Way\n",
      "Rescue\n",
      "Adoption\n",
      "Center\n",
      "in\n",
      "Morton\n",
      "Grove\n",
      ",\n",
      "Illinois\n",
      ".\n",
      "Erin\n",
      "Ellison\n",
      ",\n",
      "who\n",
      "works\n",
      "at\n",
      "the\n",
      "shelter\n",
      ",\n",
      "told\n",
      "BuzzFeed\n",
      "News\n",
      "he\n",
      "'s\n",
      "been\n",
      "in\n",
      "their\n",
      "care\n",
      "since\n",
      "April\n",
      "11\n",
      "when\n",
      "he\n",
      "was\n",
      "given\n",
      "up\n",
      "for\n",
      "adoption\n",
      "because\n",
      "he\n",
      "\"\n",
      "was\n",
      "n't\n",
      "meshing\n",
      "well\n",
      "with\n",
      "young\n",
      "kids\n",
      "in\n",
      "his\n",
      "home\n",
      ".\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "He\n",
      "was\n",
      "no\n",
      "doubt\n",
      "loved\n",
      "by\n",
      "his\n",
      "former\n",
      "family\n",
      "but\n",
      "maybe\n",
      "a\n",
      "little\n",
      "too\n",
      "much\n",
      ",\n",
      "\"\n",
      "she\n",
      "said\n",
      ".\n",
      "\"\n",
      "He\n",
      "needed\n",
      "a\n",
      "home\n",
      "that\n",
      "would\n",
      "love\n",
      "him\n",
      "enough\n",
      "to\n",
      "help\n",
      "him\n",
      "trim\n",
      "down\n",
      ".\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "7\n",
      "-\n",
      "year\n",
      "-\n",
      "old\n",
      "cat\n",
      "is\n",
      "polydactyl\n",
      ",\n",
      "meaning\n",
      "he\n",
      "has\n",
      "a\n",
      "few\n",
      "extra\n",
      "toes\n",
      ".\n",
      "He\n",
      "also\n",
      "has\n",
      "a\n",
      "strange\n",
      "habit\n",
      "of\n",
      "standing\n",
      "on\n",
      "his\n",
      "hind\n",
      "legs\n",
      ",\n",
      "the\n",
      "shelter\n",
      "said\n",
      "on\n",
      "Facebook\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "This\n",
      "usually\n",
      "happens\n",
      "when\n",
      "I\n",
      "want\n",
      "food\n",
      ".\n",
      "No\n",
      ",\n",
      "my\n",
      "foster\n",
      "parents\n",
      "did\n",
      "not\n",
      "teach\n",
      "me\n",
      "this\n",
      ".\n",
      "They\n",
      "are\n",
      "not\n",
      "sure\n",
      "how\n",
      "I\n",
      "learned\n",
      ",\n",
      "”\n",
      "the\n",
      "shelter\n",
      "said\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "’s\n",
      "now\n",
      "on\n",
      "a\n",
      "diet\n",
      "and\n",
      "“\n",
      "walking\n",
      ",\n",
      "playing\n",
      ",\n",
      "and\n",
      "doing\n",
      "tricks\n",
      "”\n",
      "so\n",
      "he\n",
      "can\n",
      "lose\n",
      "some\n",
      "weight\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Bruno\n",
      "also\n",
      "apparently\n",
      "loves\n",
      "to\n",
      "be\n",
      "petted\n",
      "while\n",
      "he\n",
      "eats\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "It\n",
      "took\n",
      "my\n",
      "foster\n",
      "mom\n",
      "a\n",
      "little\n",
      "time\n",
      "to\n",
      "realize\n",
      "what\n",
      "I\n",
      "was\n",
      "meowing\n",
      "about\n",
      ",\n",
      "since\n",
      "she\n",
      "had\n",
      "just\n",
      "put\n",
      "food\n",
      "in\n",
      "my\n",
      "bowl\n",
      ",\n",
      "”\n",
      "the\n",
      "shelter\n",
      "said\n",
      ".\n",
      "“\n",
      "Soon\n",
      "she\n",
      "found\n",
      "out\n",
      "it\n",
      "’s\n",
      "because\n",
      "I\n",
      "want\n",
      "pets\n",
      "while\n",
      "I\n",
      "eats\n",
      "!\n",
      "I\n",
      "will\n",
      "still\n",
      "eat\n",
      "if\n",
      "you\n",
      "do\n",
      "n’t\n",
      "pet\n",
      "me\n",
      ",\n",
      "but\n",
      "I\n",
      "will\n",
      "meow\n",
      "more\n",
      "and\n",
      "stare\n",
      "at\n",
      "you\n",
      "for\n",
      "a\n",
      "while\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "also\n",
      "drinks\n",
      "a\n",
      "lot\n",
      "of\n",
      "water\n",
      ",\n",
      "but\n",
      "is\n",
      "very\n",
      "particular\n",
      "about\n",
      "it\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "I\n",
      "never\n",
      "drink\n",
      "the\n",
      "water\n",
      "in\n",
      "the\n",
      "kitchen\n",
      "where\n",
      "my\n",
      "food\n",
      "is\n",
      ".\n",
      "I\n",
      "only\n",
      "drink\n",
      "the\n",
      "water\n",
      "that\n",
      "was\n",
      "put\n",
      "in\n",
      "a\n",
      "completely\n",
      "different\n",
      "room\n",
      ",\n",
      "”\n",
      "the\n",
      "shelter\n",
      "wrote\n",
      ".\n",
      "“\n",
      "If\n",
      "you\n",
      "have\n",
      "a\n",
      "larger\n",
      "house\n",
      ",\n",
      "perhaps\n",
      "put\n",
      "multiple\n",
      "bowls\n",
      "of\n",
      "water\n",
      "around\n",
      "for\n",
      "me\n",
      "and\n",
      "be\n",
      "sure\n",
      "to\n",
      "give\n",
      "me\n",
      "fresh\n",
      "water\n",
      "at\n",
      "least\n",
      "once\n",
      "day\n",
      "?\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "Yes\n",
      ",\n",
      "I\n",
      "know\n",
      "I\n",
      "am\n",
      "EXTRA\n",
      ",\n",
      "”\n",
      "they\n",
      "wrote\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Besides\n",
      "getting\n",
      "pets\n",
      "while\n",
      "eating\n",
      "and\n",
      "staying\n",
      "hydrated\n",
      ",\n",
      "Bruno\n",
      "’s\n",
      "hobbies\n",
      "are\n",
      "simple\n",
      ":\n",
      "lying\n",
      "down\n",
      "and\n",
      ",\n",
      "well\n",
      ",\n",
      "getting\n",
      "more\n",
      "pets\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "When\n",
      "I\n",
      "am\n",
      "in\n",
      "a\n",
      "normal\n",
      "home\n",
      ",\n",
      "most\n",
      "of\n",
      "my\n",
      "day\n",
      "is\n",
      "spent\n",
      "laying\n",
      "around\n",
      ",\n",
      "but\n",
      "never\n",
      "far\n",
      "from\n",
      "my\n",
      "family\n",
      ".\n",
      "I\n",
      "usually\n",
      "prefer\n",
      "to\n",
      "lay\n",
      "on\n",
      "the\n",
      "floor\n",
      "or\n",
      "right\n",
      "next\n",
      "to\n",
      "you\n",
      ",\n",
      "but\n",
      "occasionally\n",
      "I\n",
      "like\n",
      "to\n",
      "be\n",
      "a\n",
      "lap\n",
      "-\n",
      "cat\n",
      ",\n",
      "”\n",
      "the\n",
      "shelter\n",
      "said\n",
      ".\n",
      "“\n",
      "I\n",
      "also\n",
      "really\n",
      "like\n",
      "playing\n",
      "with\n",
      "my\n",
      "feather\n",
      "wand\n",
      "toy\n",
      ".\n",
      "Not\n",
      "so\n",
      "much\n",
      "my\n",
      "other\n",
      "toys\n",
      "or\n",
      "scratchers\n",
      ",\n",
      "though\n",
      ".\n",
      "I\n",
      "do\n",
      "like\n",
      "to\n",
      "sleep\n",
      "with\n",
      "my\n",
      "foster\n",
      "parents\n",
      ",\n",
      "but\n",
      "at\n",
      "the\n",
      "end\n",
      "of\n",
      "the\n",
      "bed\n",
      "so\n",
      "you\n",
      "still\n",
      "have\n",
      "room\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "also\n",
      "likes\n",
      "“\n",
      "when\n",
      "you\n",
      "scratch\n",
      "the\n",
      "sides\n",
      "of\n",
      "my\n",
      "face\n",
      "and\n",
      "neck\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "I\n",
      "like\n",
      "to\n",
      "be\n",
      "pet\n",
      "on\n",
      "the\n",
      "top\n",
      "of\n",
      "my\n",
      "head\n",
      "and\n",
      "spine\n",
      "only\n",
      ".\n",
      "I\n",
      "know\n",
      "my\n",
      "tummy\n",
      "is\n",
      "so\n",
      "tempting\n",
      "to\n",
      "touch\n",
      ",\n",
      "but\n",
      "I\n",
      "would\n",
      "prefer\n",
      "if\n",
      "you\n",
      "did\n",
      "n’t\n",
      ",\n",
      "”\n",
      "they\n",
      "said\n",
      ".\n",
      "“\n",
      "I\n",
      "may\n",
      "swat\n",
      "my\n",
      "hand\n",
      "and\n",
      "pretend\n",
      "to\n",
      "bite\n",
      "if\n",
      "you\n",
      "do\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "Video\n",
      "shows\n",
      "Bruno\n",
      "standing\n",
      "on\n",
      "his\n",
      "hind\n",
      "legs\n",
      ",\n",
      "purring\n",
      "like\n",
      "the\n",
      "furry\n",
      "boss\n",
      "that\n",
      "he\n",
      "is\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Ellison\n",
      "said\n",
      "Bruno\n",
      "has\n",
      "been\n",
      "making\n",
      "big\n",
      "gains\n",
      "(\n",
      "or\n",
      ",\n",
      "rather\n",
      ",\n",
      "losses\n",
      ")\n",
      "with\n",
      "his\n",
      "foster\n",
      "family\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "The\n",
      "foster\n",
      "home\n",
      "understood\n",
      "the\n",
      "importance\n",
      "of\n",
      "Bruno\n",
      "loosing\n",
      "weight\n",
      "if\n",
      "he\n",
      "was\n",
      "going\n",
      "to\n",
      "live\n",
      "to\n",
      "be\n",
      "an\n",
      "old\n",
      "man\n",
      ",\n",
      "\"\n",
      "she\n",
      "said\n",
      ".\n",
      "\"\n",
      "He\n",
      "has\n",
      "been\n",
      "thriving\n",
      "with\n",
      "his\n",
      "foster\n",
      "and\n",
      "has\n",
      "become\n",
      "a\n",
      "much\n",
      "more\n",
      "active\n",
      "cat\n",
      ".\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "He\n",
      "is\n",
      "an\n",
      "awesome\n",
      "boy\n",
      "who\n",
      "is\n",
      "going\n",
      "to\n",
      "do\n",
      "great\n",
      "with\n",
      "a\n",
      "family\n",
      "who\n",
      "can\n",
      "shower\n",
      "him\n",
      "with\n",
      "affection\n",
      "and\n",
      "continue\n",
      "his\n",
      "weight\n",
      "loss\n",
      "journey\n",
      ".\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "Potential\n",
      "adopters\n",
      "can\n",
      "stop\n",
      "by\n",
      "to\n",
      "meet\n",
      "him\n",
      "at\n",
      "the\n",
      "shelter\n",
      "starting\n",
      "this\n",
      "weekend\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can count some words by:\n",
    "- turning the words into a list\n",
    "- turning that list into a pandas data frame\n",
    "- counting the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for token in doc:\n",
    "    rows.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'Bruno', ',', 'and', 'he', '’s', 'a', '25', '-', 'pound', 'cat', 'who', '’s', 'currently', 'up', 'for', 'adoption', 'at', 'the', 'Wright', '-', 'Way', 'Rescue', 'Adoption', 'Center', 'in', 'Morton', 'Grove', ',', 'Illinois', '.', 'Erin', 'Ellison', ',', 'who', 'works', 'at', 'the', 'shelter', ',', 'told', 'BuzzFeed', 'News', 'he', \"'s\", 'been', 'in', 'their', 'care', 'since', 'April', '11', 'when', 'he', 'was', 'given', 'up', 'for', 'adoption', 'because', 'he', '\"', 'was', \"n't\", 'meshing', 'well', 'with', 'young', 'kids', 'in', 'his', 'home', '.', '\"', '\\n\\n', '\"', 'He', 'was', 'no', 'doubt', 'loved', 'by', 'his', 'former', 'family', 'but', 'maybe', 'a', 'little', 'too', 'much', ',', '\"', 'she', 'said', '.', '\"', 'He', 'needed', 'a', 'home', 'that', 'would', 'love', 'him', 'enough', 'to', 'help', 'him', 'trim', 'down', '.', '\"', '\\n\\n', 'The', '7', '-', 'year', '-', 'old', 'cat', 'is', 'polydactyl', ',', 'meaning', 'he', 'has', 'a', 'few', 'extra', 'toes', '.', 'He', 'also', 'has', 'a', 'strange', 'habit', 'of', 'standing', 'on', 'his', 'hind', 'legs', ',', 'the', 'shelter', 'said', 'on', 'Facebook', '.', '\\n\\n', '“', 'This', 'usually', 'happens', 'when', 'I', 'want', 'food', '.', 'No', ',', 'my', 'foster', 'parents', 'did', 'not', 'teach', 'me', 'this', '.', 'They', 'are', 'not', 'sure', 'how', 'I', 'learned', ',', '”', 'the', 'shelter', 'said', '.', '\\n\\n', 'He', '’s', 'now', 'on', 'a', 'diet', 'and', '“', 'walking', ',', 'playing', ',', 'and', 'doing', 'tricks', '”', 'so', 'he', 'can', 'lose', 'some', 'weight', '.', '\\n\\n', 'Bruno', 'also', 'apparently', 'loves', 'to', 'be', 'petted', 'while', 'he', 'eats', '.', '\\n\\n', '“', 'It', 'took', 'my', 'foster', 'mom', 'a', 'little', 'time', 'to', 'realize', 'what', 'I', 'was', 'meowing', 'about', ',', 'since', 'she', 'had', 'just', 'put', 'food', 'in', 'my', 'bowl', ',', '”', 'the', 'shelter', 'said', '.', '“', 'Soon', 'she', 'found', 'out', 'it', '’s', 'because', 'I', 'want', 'pets', 'while', 'I', 'eats', '!', 'I', 'will', 'still', 'eat', 'if', 'you', 'do', 'n’t', 'pet', 'me', ',', 'but', 'I', 'will', 'meow', 'more', 'and', 'stare', 'at', 'you', 'for', 'a', 'while', '.', '”', '\\n\\n', 'He', 'also', 'drinks', 'a', 'lot', 'of', 'water', ',', 'but', 'is', 'very', 'particular', 'about', 'it', '.', '\\n\\n', '“', 'I', 'never', 'drink', 'the', 'water', 'in', 'the', 'kitchen', 'where', 'my', 'food', 'is', '.', 'I', 'only', 'drink', 'the', 'water', 'that', 'was', 'put', 'in', 'a', 'completely', 'different', 'room', ',', '”', 'the', 'shelter', 'wrote', '.', '“', 'If', 'you', 'have', 'a', 'larger', 'house', ',', 'perhaps', 'put', 'multiple', 'bowls', 'of', 'water', 'around', 'for', 'me', 'and', 'be', 'sure', 'to', 'give', 'me', 'fresh', 'water', 'at', 'least', 'once', 'day', '?', '”', '\\n\\n', '“', 'Yes', ',', 'I', 'know', 'I', 'am', 'EXTRA', ',', '”', 'they', 'wrote', '.', '\\n\\n', 'Besides', 'getting', 'pets', 'while', 'eating', 'and', 'staying', 'hydrated', ',', 'Bruno', '’s', 'hobbies', 'are', 'simple', ':', 'lying', 'down', 'and', ',', 'well', ',', 'getting', 'more', 'pets', '.', '\\n\\n', '“', 'When', 'I', 'am', 'in', 'a', 'normal', 'home', ',', 'most', 'of', 'my', 'day', 'is', 'spent', 'laying', 'around', ',', 'but', 'never', 'far', 'from', 'my', 'family', '.', 'I', 'usually', 'prefer', 'to', 'lay', 'on', 'the', 'floor', 'or', 'right', 'next', 'to', 'you', ',', 'but', 'occasionally', 'I', 'like', 'to', 'be', 'a', 'lap', '-', 'cat', ',', '”', 'the', 'shelter', 'said', '.', '“', 'I', 'also', 'really', 'like', 'playing', 'with', 'my', 'feather', 'wand', 'toy', '.', 'Not', 'so', 'much', 'my', 'other', 'toys', 'or', 'scratchers', ',', 'though', '.', 'I', 'do', 'like', 'to', 'sleep', 'with', 'my', 'foster', 'parents', ',', 'but', 'at', 'the', 'end', 'of', 'the', 'bed', 'so', 'you', 'still', 'have', 'room', '.', '”', '\\n\\n', 'He', 'also', 'likes', '“', 'when', 'you', 'scratch', 'the', 'sides', 'of', 'my', 'face', 'and', 'neck', '.', '”', '\\n\\n', '“', 'I', 'like', 'to', 'be', 'pet', 'on', 'the', 'top', 'of', 'my', 'head', 'and', 'spine', 'only', '.', 'I', 'know', 'my', 'tummy', 'is', 'so', 'tempting', 'to', 'touch', ',', 'but', 'I', 'would', 'prefer', 'if', 'you', 'did', 'n’t', ',', '”', 'they', 'said', '.', '“', 'I', 'may', 'swat', 'my', 'hand', 'and', 'pretend', 'to', 'bite', 'if', 'you', 'do', '.', '”', '\\n\\n', 'Video', 'shows', 'Bruno', 'standing', 'on', 'his', 'hind', 'legs', ',', 'purring', 'like', 'the', 'furry', 'boss', 'that', 'he', 'is', '.', '\\n\\n', 'Ellison', 'said', 'Bruno', 'has', 'been', 'making', 'big', 'gains', '(', 'or', ',', 'rather', ',', 'losses', ')', 'with', 'his', 'foster', 'family', '.', '\\n\\n', '\"', 'The', 'foster', 'home', 'understood', 'the', 'importance', 'of', 'Bruno', 'loosing', 'weight', 'if', 'he', 'was', 'going', 'to', 'live', 'to', 'be', 'an', 'old', 'man', ',', '\"', 'she', 'said', '.', '\"', 'He', 'has', 'been', 'thriving', 'with', 'his', 'foster', 'and', 'has', 'become', 'a', 'much', 'more', 'active', 'cat', '.', '\"', '\\n\\n', '\"', 'He', 'is', 'an', 'awesome', 'boy', 'who', 'is', 'going', 'to', 'do', 'great', 'with', 'a', 'family', 'who', 'can', 'shower', 'him', 'with', 'affection', 'and', 'continue', 'his', 'weight', 'loss', 'journey', '.', '\"', '\\n\\n', 'Potential', 'adopters', 'can', 'stop', 'by', 'to', 'meet', 'him', 'at', 'the', 'shelter', 'starting', 'this', 'weekend', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word\n",
       "0   This\n",
       "1     is\n",
       "2  Bruno\n",
       "3      ,\n",
       "4    and"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dataframe = pd.DataFrame(rows)\n",
    "word_dataframe.columns = ['word']\n",
    "word_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0     ,     34\n",
       "1     .     33\n",
       "2     I     20\n",
       "3   the     18\n",
       "4  \\n\\n     18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = word_dataframe['word'].value_counts().reset_index()\n",
    "word_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\n</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "word      \n",
       "\\n       1\n",
       "\\n\\n    18\n",
       "!        1\n",
       "\"       12\n",
       "'s       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_alt = word_dataframe.groupby('word').agg({\"word\":\"count\"})\n",
    "word_count_alt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count.to_csv('../output/word_count.csv', index=False)\n",
    "word_count_alt.to_csv('../output/word_count2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
